Thoughts about loaders:

I. Why another ETL loader?

Many existing ETL loaders are excessively complex and many are command-line
unfriendly.  etl_wiz will be purely command-line oriented, as simple as the
rather complex problem of ETL allows, and intended for use in scripted and
other command-line environments.  

Also, most ETL loaders are specific to a single database.  etl_wiz will
be architected to handle multiple types of database, ie MySQL to PostgreSQL
or vice-versa.

II. ETL_Wiz implementation in C

etl_wiz is coded in C and optimized for large-scale loading, where
"large scale" means "as big as possible and run as fast as possible", but
hopefully hundreds of thousands or millions of records per second.  Also,
the design should allow for loads to multiple database targets, as many big
environments are multi-instance.  

Why C?  Because I know it well and know how to write fast code in it.

III. Third-party library policy

I will minimize use of third-party libraries except where they can't
be avoided, such as database connector packages, although the C standard
library will be used where appropriate.

This means that there will be some "wheel reinvention" in this code, but
so be it.

This library policy is to minimize support hassles, packaging complexity, and
license issues. 

IV.  The overall design

Like most loader-type applications, it will have an input-process-output 
design.  The input will accept records from the source (whether it's a datafile
or a source database), "process" them using mapping directives specified in 
the input data description file, and the "processed" records will then be
loaded to one or more data sources as specified in the output specification
file.  

The largest single performance optimization is that INSERT statements
generated by etl_wiz are as long as possible.  Modern DB engines process
long INSERT statements very efficiently, so this will allow an optimal load
speed.

COMMIT options can be set, allowing everything from commit-every-record (very
slow and not recommended unless there's a Very Good Reason for it) to COMMIT
every bulk-INSERT (a good middle ground) to COMMIT only after a load has 
completed (may be problematic for Very Large loads).

The default will be COMMIT every bulk-INSERT.

V.  Config files

Configuration files are intended for human editing and will use something like
the "TOML format" discussed here (although it may not precisely be this format)

https://toml.io/en

The "TOML" format is used for cnf files in MySQL.

a. The db connections file

This contains info needed to connect to specific database instances,
such as hostname, host type, host port, user name, user password, and the
database name.  There may be db vendor specific data here.

Early versions of etl_wiz will support a single source and target database,
although later versions may include support for sharded targets (ie, targeting
multiple db instances based on logic specified using input description logic.

b. Input data description file

The input data description file describes the format of input data
This will be separate from the db connection file so that we can allow
the same data description file to be used for loads to multiple database 
instances.  

This will include the following:

o Description of the input data with things like custom delimiters,
  custom record terminator characters, etc.
o For fixed-width formats, this will be where we store the record offsets
o Remapping directives will also be stored here. 
o In future versions where we do loads between databases, the extraction query
  will be stored here.

c. Runtime behavior description file

This will contain information such as 

1. How to behave upon errors.  Stop on first error?  Stop after N errors?
Continue until done, even though there are some errors?  
2. Where to put logging output.
3. Any other runtime behavior specifiers.

3. Runtime execution

A command line will look something like

etl_wiz -d [db-conf] -i [input-conf] -r [runtime-conf] input_file.csv

Environment variables:

ETL_DB_CONF - specifies a path to the db config file
ETL_INPUT_CONF - specifies a path to an input config file
ETL_RUNTIME_CONF - specifies a path to the runtime config file

Upgrade Plans

Version 1: CSV to MySQL as a target
Version 2: Add fixed record format files and Postgres as a target
Version 3: Use a database as a data source as well as a target
